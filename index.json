[{"categories":["hardware"],"content":"Verilog/VHDL加密浅析 ","date":"2021-08-16","objectID":"/verilog-crypt/:0:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"背景 在EDA开发流程中，涉及了很多不同厂商的软件及IP（Intelligence Property），当用户购买了IP后，如何既能保护开发者的利益，又能够方便用户使用？每家厂商都有着自己的加密方案，有的采用了binary的格式，有的采用的是text的格式，当整个flow中采用了多个EDA厂家的产品时，互操作性很难保证，多家EDA厂商共同发布了IEEE1735这个规范，用于加密Verilog/VHDL语言的代码。 ","date":"2021-08-16","objectID":"/verilog-crypt/:1:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"IEEE-1735规范 IEEE-1735规范分为V1和V2两个版本，目前主要使用的是V1。 简单来说，采用的是对称加密算法使用随机生成的密钥(data_key)对代码进行加密并得到加密后的数据，然后将data_key使用每家EDA厂家自己的RSA私钥加密得到encrypted key，放在key_block中。另外，将使用data_key加密后的数据存放在data_block中，加上EDA厂家及RSA key name构成一个encrypted envelope替换掉原始文件中的内容。 对数据进行加密的算法主要采用的是AES-CBC，也支持其他算法比如blowfish-cbc等，这个算法也会作为必要的信息包含在加密后描述信息中。对加密数据和RSA加密后的密钥一般采用的编码方式为BASE64，也有少数采用UUencode的方式。 例如下面的加密样本 `pragma protect begin_protected `pragma protect version = 1 `pragma protect key_keyowner = \"AAAA\", key_keyname= \"BBBB\", key_method = \"rsa\" `pragma protect key_block ARIxiMyY/u314g+0H+bMrO2GAJk/FvLIb/AN0hFwJJ3PSmx56gBdOr1Erp45F1i68slteEk2xMxc 7qNtYVS/QcjeM9tl1pE9lqvCtcev/w+cLOdLwVNDWrx+UjXKJyJdZl4TQpNkGhg3jXezLUm7Y9t5 CIG3ztpiaUgwg4uqJDlcJ/DU2c4axryeYy4eJbDz8eBbB/bIkj8ghSMvBZurysZr+z5yMnLIzvNF FTLCN7D3yz+ymWfmo6nub5jEQZq5fKim7L3VYfA38v4Hs1GcyWAQpn32zYJoaBThREZy5hDQ5wQx JHxS2NPI+/U8EddEzettvGVl2WQamTv4aCfylA== `pragma protect data_method = \"AES128-CBC\" `pragma protect data_block u+2vP4WS1vBobqzn052K08Twj4xC9k1w//2Xfp5dqULLFuUvuS5B4VtclRId07+/lwpkBmy5OKPa H3N+t0hmaGzNtMkPtXP8EPDfJTmnQGNP6hfeL1ZFmGLdbAiT7GFJaeXA1EJcFtL9zocScGoYBg7p nv1qpOPlZN4CFV/+xKG8MMvCgMRNhGkKqRKAf4QCTzIa2mUta1DjacltrYKoGhOK8BI8nTSipKdp /NSfW/kkMrtnFmQAYVlPs+/H0Dyo1EC0n2g8c5Ho87we+oUX6s1eiMVSdkM5AcIpq8USxIiU/A48 0NmHieAis8b3ujiVkLO84ZeyS4LNioXMAy45w3jbSfTPDtg3s5SXbFQvUULYFylpHHlQJs0bXkrF `pragma protect end_protected 加密参数： parameter comment version 1 密钥加密类型 rsa 密钥所有者 AAA 密钥名称 BBB 数据加密算法 AES128-CBC ","date":"2021-08-16","objectID":"/verilog-crypt/:2:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"自定义加密方式 虽然主流的EDA厂家都支持IEEE-1735，各个EDA厂家也有大量遗留IP采用的是自定义的格式。比如Cadence有不少IP都是采用RC5算法对data key进行加密；Synopsys由于收购了不少的EDA厂商，因此加密算法也各不相同，比如之前Synplicity家的产品如Synplify有一种怀疑是简单替换加密的方式，而VCS也自定义加密方式VCS003等，后面会列出我收集到的各种加密格式的样本列表。 ","date":"2021-08-16","objectID":"/verilog-crypt/:3:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"IP代码混淆 有一些厂商没有对代码直接进行加密，而是采用了混淆的方式来保护IP的代码。也有一些厂商是先混淆，然后再加密。 混淆虽然能够避免用户直接看到代码，但是还是无法抵抗手动还原。 Aldec就提供一个脚本来进行代码的混淆。 ","date":"2021-08-16","objectID":"/verilog-crypt/:4:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"RSA密钥废弃 为了保证互操作性，各大EDA厂商会将RSA的公钥公布到网上或者包含在自己的提供的IP保护工具中，方便第三方加密自己的IP。同时为了避免私钥泄露导致的代码被解密，各大EDA厂商也会经常更换新的RSA公钥，而已泄露的私钥将被废弃，不再推荐用户使用。比如，Mentor的MGC-VERIF-SIM-RSA-1和Aldec的ALDEC08_001就已经被废弃了。 ","date":"2021-08-16","objectID":"/verilog-crypt/:5:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"已公开的RSA私钥 在网上可以找到很多被破解公开的私钥： MGC-DVT-MT cds_key SNPS-VCS-RSA-1 xilinx_2016_05 ALDEC08_001 另外，还有一篇帖子对各种密钥的使用做了说明。 ","date":"2021-08-16","objectID":"/verilog-crypt/:6:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"代码解密 为了解密IEEE-1735加密的代码，只需要得到对应的RSA私钥即可。获取RSA私钥有两种方式： 通过公钥计算出私钥 通过逆向工程的方式，从综合工具中找到私钥 ","date":"2021-08-16","objectID":"/verilog-crypt/:7:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"通过公钥计算私钥 当RSA密钥长度比较短时，可以通过暴力穷举的方式进行因数分解计算其私钥，目前主流的方法是NFS。可以使用GNNFS和MSEIVE等工具来进行，我尝试过分解一个512bit的RSA私钥，在目前主流的配置上不到1周时间可以分解成功。具体流程可以参考看雪的两篇贴子。 附上CDS_RSA_KEY的公钥，有兴趣的可以自己分解一下： -----BEGIN PUBLIC KEY----- MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKz/7kNnLtjRpDHsWhg+zJOB1oSRfUPZ Odt3xmDEZkOvDHh4qxqcZQ08noEYUzuTVqLT0k9Fa2RAfNgOqzVudVsCAwEAAQ== -----END PUBLIC KEY----- 当RSA密钥长度为1024甚至2048的时候，暴力因数分解所需要的时间就是不可接受的了。 ","date":"2021-08-16","objectID":"/verilog-crypt/:7:1","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"逆向工程找到私钥 由于EDA工具最终识别的是Verilog/VHDL代码，因此必须将加密后的代码进行解密才能继续后续的代码解析/综合等工作，因此综合工具中必然包含了其RSA解密说必须的私钥。为了避免被逆向出私钥，EDA工具也是对私钥进行了很多的保护。从我遇到的情况来看，主要有如下几种： 不加密，直接字符串保存 直接搜索MII这个特征字符串，基本就很容易定位了 对私钥进行加密 需要在解密后才能得到MII打头的私钥 不保存完整的私钥，而是保存RSA的p/q/e等参数，直接采用p/q/e进行解密 根据获取的p/q/e计算出phi，n和d，然后编码为ASN.1格式并base64后加上头尾即可 可以参考rsatool 对解密过程进行混淆 去除混淆，找到密钥 ","date":"2021-08-16","objectID":"/verilog-crypt/:7:2","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"解密代码 得到私钥后，可以使用RSA来解密key_block来得到data_key，使用data_key使用data_method中指定的算法来解密data_block中的数据。 简单的解密可以手动拆分文件，然后使用openssl来完成rsa和aes-cbc等算法的解密。对比较复杂的文件（比如一个文件中包含多个envelop）可以采用python来完成代码解析到解密的全过程，具体代码可以参考p1735_decryptor这个项目。 具体的解密过程中还有很多细节需要处理，比如IV的获取和处理，解密后密钥和数据中填充内容的去除等。 ","date":"2021-08-16","objectID":"/verilog-crypt/:7:3","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"样本列表 IEEE-1735的加密文件样本： vendor name key name comment Synopsys SNPS-VCS-RSA-1 RSA Synopsys SNPS-VCS-RSA-2 RSA Cadence Design Systems. CDS_RSA_KEY RSA Cadence Design Systems. CDS_RSA_KEY_VER_1 RSA Mentor Graphics Corporation MGC-VERIF-SIM-RSA-1 RSA，已废弃 Mentor Graphics Corporation MGC-VERIF-SIM-RSA-2 RSA MTI MGC-DVT-MTI RSA Xilinx xilinx_2016_05 RSA Synplicity SYNP05_001 RSA Synplicity SYNP15_1 RSA ATRENTA ATR-SG-2015-RSA-3 RSA Aldec ALDEC08_001 RSA，已废弃 Aldec ALDEC15_001 RSA 非标准加密方式： vendor name key name comment Cadence Design Systems. cds_key RC5，IUS/Xcelium出现过两个版本不同的key Cadence Design Systems. cds_key RC5/AES，Spectre有四个版本不同的key Cadence Design Systems. cds_nc_key RC5 Cadence Design Systems. CDS_DATA_KEY 直接加密data Synopsys VCS VCS001 加密算法VCS003，使用uuencode编码 Synopsys VCS 没有keyname和keymethod，直接使用`protected和`endprotected包裹，数据似乎也是采用uuencode编码，可能与上一种是同样的加密方式。出现在VIP的svp文件中。 Synopsys DC/VCS 使用synenc进行数据加密，为binary格式，一般头为\"D2 49 69 32 E3 B3 2A F2 FF 00 C3 89 22 C1 08 74\"，后缀为一般为.e，能支持vhdl/verilog/tcl/perl/dc_shell等格式的加密。DC中的DW库一般以这种格式加密，IP/VIP中也有很多文件采用这种方式加密。加密后数据DC/VCS/Synplify都可以读取 Intel Quartus 使用binary文件，AES密码保存在FlexLM license的vendor_string中 ","date":"2021-08-16","objectID":"/verilog-crypt/:7:4","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"总结 为了保护IP，各大EDA厂商使用IEEE-1735进行保护，但是究其本质，IEEE-1735的V1版标准是无法避免私钥泄露或者被逆向工程利用的。 我通过对EDA工具的逆向工程，已经获取了上面这些密钥并编写了完整的解密工具。 ","date":"2021-08-16","objectID":"/verilog-crypt/:8:0","tags":["Verilog","SystemVerilog","VHDL","EDA","FPGA","reverse engineering"],"title":"Verilog/VHDL加密浅析","uri":"/verilog-crypt/"},{"categories":["hardware"],"content":"背景 最近这半年，没有更新blog，主要是因为忙于学习硬件开发，这篇post就来谈谈一个软件开发者眼中的硬件开发吧。 之前读书的时候也学过电子电路，数字逻辑，计算机组成原理等一些专业课，当时也没有太多关注硬件相关的开发，主要钻研软件开发的技术，入了C++的坑。后来，在做逆向的时候，也算是在汇编的泥潭里面摸爬滚打过，对汇编语言虽然说不上精通，但是也算有了一定的了解。之后，逐渐参与了一些FPGA相关的项目，期间也为FPGA写过driver，对硬件的了解也算是深入到了原理图，寄存器和时序图这个层级。 这一次，由于项目需要实现一个HDMI多屏同步的功能，对实时性要求非常高。虽然我们之前在软件层面已经做到了frame级别（33ms），而这次我们的目标是scanline级别（30us），通过现有的软件根本做不到。为了达成目标，我们最终选择了FPGA。而我们团队中没有人对FPGA开发有任何经验，我只好硬着头皮上了。 经过了半年的学习和开发，目前基本功能已经可以正常使用，还有一些收尾的工作正在进行，终于有时间来总(tu)结(cao)一下了。 开发语言的选择 之前做过一些FPGA相关的工作，硬件的同事主要使用的是VHDL，现在Verilog已经是主流了，VHDL的项目也越来越少，再加上Verilog号称与C语言比较类似，一开始就选择了Verilog作为主要开发语言。但是在开发的过程中，发现Verilog基本等同于软件开发的汇编语言了，根本没有数据结构的概念，只有reg和wire，而且还需要手工区分wire和reg类型，作为用惯了高级语言的我来说，感觉实在太别扭了。于是从Verilog转到了SystemVerilog，才感觉从史前到了古代。 为什么说SystemVerilog是古代呢？SystemVerilog虽然比Verilog要稍微好用一点，但是也仅仅也就只是好一点而已了。SystemVerilog大部分改进都只能在simulation的时候使用，synthesis的时候是不支持的。 另外，也简单看了下chisel等号称下一代HDL的语言，发现基本也是没太大改进。 RTL 之前没有接触数字逻辑开发的时候，RTL（寄存器传输级）这个术语我不太能理解，为什么是“寄存器”传输呢。入门后，我才恍然大悟，RTL的开发也真的就是只能在Register这个层级上捣鼓了。 组合逻辑（combinational logic）电路进行逻辑运算，在时钟边沿将结果寄存到DFF（D flip flop）中，DFF就是寄存器了。FF的输出结果作为下一级组合逻辑电路的输入，在时钟的驱动下，不断向下一级传输，就构成了RTL。 FF用于存储状态，组合逻辑电路用来将输入转换到输出，时钟用于驱动状态的变换，写RTL也就是搭建组合逻辑电路和寄存器构成的数字电路。 在HDL（Hardware Description Language）出现之前，大家都是手工搭建电路的，有种侏罗纪的感觉。出现了HDL后，终于可以不用画图了，综合工具（相当于软件里面的编译器）可以帮你把加法运算直接综合成加法器了，不用手工搭加法器电路了。不过，综合工具也就只能支持加法，位运算这些简单的操作了，乘法和除法还是不支持或者支持有限。 那么，在软件中的乘法和除法是怎么做的呢？乘法可以展开为加法或者移位，每个时钟周期做一次加法或者移位，将中间结果保存在寄存器中，多做几个时钟周期就可以了。 状态机 在编写HDL时，除了最简单的组合逻辑情况，比较复杂的设计中都会使用到FSM（有限状态机）。而不同状态的触发条件，基本上都是通过计数器来实现。 RTL的最基本单元就是FSM，不管你是使用计算器的结果作为状态转移的条件，还是使用特定的输入作为条件，本质上都是状态机。 CDC（Clock Domain Crossing） 如果所有的DFF都工作在同一个时钟域，那就是最简单的情况。但是，考虑到功耗，组合逻辑电路的复杂度不同导致的延迟差异以及不同的传输协议等问题，基本上一个设计中都包含多个不同的时钟，用于驱动不同的部分。比如memory的时钟与HDMI的时钟必然不可能使用同一个时钟。 而多个不同时钟之间的数据传输，有可能出现亚稳态，怎么避免亚稳态就构成了典型的CDC问题。CDC常见的处理方式有三种：打两（N）拍，握手机制和使用FIFO。 CDC导致的第二个问题，就是STA（静态时序分析）是无法对CDC进行正确处理的，因此需要对其进行特殊处理，要么将其路径打断（set_false_path），要么设置为多周期（set_multicycle_path)。 STA（Static Timing Analysis） 为什么一个数字逻辑电路无法跑到更高的频率？ 正如我们上面所述，数字逻辑电路中最重要的组成部分是组合逻辑电路和DFF，组合逻辑电路从输入到稳定输出是需要时间的，越复杂的电路耗时越长，而且在输出稳定前可能会出现毛刺；DFF的记录状态变化和输出之前的状态也是需要时间的，这两部分耗时加起来就约束了数字逻辑电路的最小时钟周期，从而也约束了其运行的最高频率。 我们怎么才能得到一个数字逻辑电路的最高频率呢？ STA就是用来帮助我们分析这个问题的工具，STA工具通过用户提供的约束条件和器件固有的延时，计算出数据传输路径上DFF的setup time和recovery time，当发生时序违例的时候，我们就能够有针对性的调整一些关键路径上的实现，进一步优化时序，提高电路运行的频率。 FPGA FPGA怎么做到可编程的呢？学过数字逻辑的同学都知道，所有的组合逻辑可以用LUT（lookup table）来完成。一般来说，FPGA中会将4输入LUT加上一个DFF构成一个基本的LE（逻辑单元），每个LE都可以进行对应的LUT的配置和是否使用DFF，再用连线将LE连接起来，因此就能够将我们前面所述的RTL转换到一个开关表（bitstream），表项对应每个LE内部的LUT/DFF是否使能，LE之间是否连线。 在FPGA开发中，Synthesis将HDL转换为通用的硬件表示，对应到ASIC开发的前端流程，Place\u0026Route则将通用的硬件表示映射为特定FPGA硬件中的LE及LE之间的连线，对应到ASIC开发的后端流程。 通用的FPGA Synthesis工具有Synopsys的Synplify和Mentor的Precision。Intel/Altera和Xilinx也有自己专用的Synthesis工具。Place\u0026Route由于与具体的芯片关系紧密，各家FPGA厂商都是使用的自己的工具。 FPGA中还集成了很多其他硬件，用于方便开发人员实现自己的功能，比如高速收发器用于对接外部的高速串行数据I/O，用于实现10G/40G以太网，HDMI等接口；硬核CPU用于控制；硬核memory controller可以极大的加快内存的访问速度。 数字逻辑电路的Synthesis和P\u0026R的速度实在太慢了，而且对多线程的支持也不完善，我们这个小项目一次完整的综合布局布线流程需要20-30分钟。 调试与仿真 RTL开发很难进行调试，常见的拍错方式是进行simulation（仿真）。Simulation就是给予待测试单元（UUT）输入激励，然后通过simulator模拟硬件工作，对激励给出输出信号，simulator可以记录module内部信号的变化，用waveform的形式进行展示。相比于软件的debugger，simulator能够记录所有的信号变化，类似于tracer。对于信号中出现的错误，分析waveform，并定位出root cause是数字逻辑开发人员的基本功。 目前主流的Simulator有Synopsys的VCS+Verdi，Cadence的NCVerilog/Xcelium和Mentor的ModelSim/QuestaSim。另外，Xilinx的Vivado中也有集成自家的Simulator。还有Aldec的ActiveHDL和Riviera Pro这种比较小众的Simulator。 Simulator是EDA软件中为数不多有着开源替代方案的领域。Verilator和Icarus Verilog也是不错的选择，唯一的遗憾是Verilator对SystemVerilog和UVM的支持还不够好，从issue来看，官方也正在着手改进，希望能够尽快支持最新的SystemVerilog和UVM标准。 Mentor的ModelSim集成在主要的FPGA厂商的IDE中，对于比较小的设计，可以免费使用。但是，作为主流EDA厂家的Simulator，ModelSim实在算不上是好用，工具栏的位置每次切换布局都出问题，拖动窗口的时候反应极为迟缓，怎么都想不通为什么这么个破玩意居然可以买到好几万。 Simulation的速度也是非常慢，很多Simulator只能单线程运行，多线程运行需要额外加钱，而且加速比也不高，甚至需要手工分割任务。免费版的ModelSim按文档说法只有收费版本的1/4的速度，还有零有整的，怀疑里面每个操作都要额外多loop三次。 Lint 由于无论是仿真还是综合都需要大量时间，Lint工具也成了必不可少的组成部分。很多应该在语言层面加以禁止的问题，只有通过Lint工具才能发现。Lint工具中比较好的有Synopsys的SpyGlass，Aldec的Alint pro。 Verification 类似于软件中的TDD（Test Driven Development），RTL设计中Verification也是用来对RTL design做测试的重要步骤，目前主流使用的是UVM，号称是“方法学","date":"2021-07-06","objectID":"/playing-with-hardware/:0:0","tags":["Verilog","SystemVerilog","hardware","FPGA"],"title":"软件开发者的硬件开发之旅","uri":"/playing-with-hardware/"},{"categories":["golang"],"content":"应用场景 在后端系统中，可能需要支持数据导出为xlsx文件的功能，当数据量很大时，如果先创建文件，然后通过HTTP接口进行下载，则在文件生成前，浏览器端会出现下载已经开始，但是没有任何数据传输的情况，用户体验很差，而且在服务器端要浪费磁盘空间和CPU时间来进行文件打包，下载完成/中断后还需要删除临时文件。 类似的情况还有数据打包操作，比如在网盘应用中，用户希望一次性下载多个文件，而浏览器可能会拦截除第一个外的其他文件下载，也会导致用户体验变差。在百度网盘和google drive中，当需要下载一个目录时，会将这个目录打包为一个zip文件后再下载，从而规避浏览器的这个限制。 ","date":"2021-01-03","objectID":"/create-stream-xlsx/:1:0","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"xlsx文件格式 要想生成xlsx文件，需要了解其文件格式，根据Ecma Office Open XML Part 2可知，xlsx是一个zip文件，所以我们先来看看zip文件格式。 ","date":"2021-01-03","objectID":"/create-stream-xlsx/:2:0","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"zip文件格式简介 从上图可以看出，zip文件格式分为多个文件记录和central directory两部分。文件记录包括local file header和文件内容（还可以包含可选的data descriptor和encryption header）。文件记录可以分布在zip中的任意位置，文件记录之间可以有空隙。在zip文件最后有一个central directory来指明文件记录在zip中所在位置。 之所以采用这种布局，是为了支持： 生成流式zip文件 添加新文件不需要重新打包旧的文件，只需要在文件结尾处添加新文件并重新生成新的central directory 在zip文件头添加其他数据，如自解压头 在其他文件中嵌入zip文件 上面的图中还有一个重要的部分没有绘制出来，就是data descriptor，根据zip format SPEC： [local file header 1] [encryption header 1] [file data 1] [data descriptor 1] . . . [local file header n] [encryption header n] [file data n] [data descriptor n] [archive decryption header] [archive extra data record] [central directory header 1] . . . [central directory header n] [zip64 end of central directory record] [zip64 end of central directory locator] [end of central directory record] 我们可以看到一个文件记录最开始是一个local file header，后面是可选的encryption header，接下来是文件内容，最后是一个可选的data descriptor。data descriptor就是用于支持流式zip文件生成而必须的部分。 ","date":"2021-01-03","objectID":"/create-stream-xlsx/:2:1","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"文件记录 下面我们详细说明一下文件记录中的各个组成部分： local file header local file header signature 4 bytes (0x04034b50) version needed to extract 2 bytes general purpose bit flag 2 bytes compression method 2 bytes last mod file time 2 bytes last mod file date 2 bytes crc-32 4 bytes compressed size 4 bytes uncompressed size 4 bytes file name length 2 bytes extra field length 2 bytes file name (variable size) extra field (variable size) data descriptor crc-32 4 bytes compressed size 4 bytes uncompressed size 4 bytes 可以看到，在local file header和data descriptor中都包含了crc-32、compressed size和uncompressed size。 为什么要重复记录呢？当文件内容是实时生成的时候，这三个值都是无法预先知道的，只有在写入完成后才能得到。因此在生成流式文件的时候： 在写入的local file header中设置general purpose bit flag的bit 3为1，指明这三个值需要从data descriptor中读取，并将其值都设置为0； 写入数据，同时计算crc-32，记录compressed size和uncompressed size； 将正确的crc-32、compressed size和uncompressed size写入data descriptor中； 将所有写入文件的偏移写入到central directory中，完成文件传输。 当需要写入的文件已经存在时，我们甚至可以预先计算好文件对应的crc-32值，当生成流式zip文件时，compression method字段采用store(0)模式，这种模式下文件数据不压缩，compressed size和uncompressed size大小一致。此时，zip文件中所有数据的位置和值都是可以预先确定的，从而支持断点续传和多线程下载流式zip文件，具体实现可以参考nginx zip module。这种方式可以用于在网盘应用中下载包含多个文件的zip包， ","date":"2021-01-03","objectID":"/create-stream-xlsx/:2:2","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"xlsx文件内容 简单来说，xlsx就是一个包含多个xml文件的zip包，其中大部分是固定内容的xml文件。我们可以新建一个空的xlsx文件，unzip后就能看到其中的文件： _rels/.rels docProps/app.xml docProps/core.xml xl/_rels/workbook.xml.rels xl/theme/theme1.xml xl/styles.xml [Content_Types].xml xl/workbook.xml xl/worksheets/sheet1.xml … 当只有一个工作簿的时候，工作簿数据一般存放在xl/worksheets/sheet1.xml文件。如果需要支持多个工作簿和其他高级功能，需要参考Standard ECMA-376 Office Open XML File Formats。 xl/worksheets/sheet1.xml文件格式如下： \u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?\u003e \u003cworksheet xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\" xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" mc:Ignorable=\"x14ac xr xr2 xr3\" xmlns:x14ac=\"http://schemas.microsoft.com/office/spreadsheetml/2009/9/ac\" xmlns:xr=\"http://schemas.microsoft.com/office/spreadsheetml/2014/revision\" xmlns:xr2=\"http://schemas.microsoft.com/office/spreadsheetml/2015/revision2\" xmlns:xr3=\"http://schemas.microsoft.com/office/spreadsheetml/2016/revision3\" xr:uid=\"{A45FA7EE-319C-4F2A-BADD-CBFF345C308D}\"\u003e \u003ccols\u003e \u003ccol min=\"1\" max=\"1\" width=\"20\" /\u003e \u003ccol min=\"2\" max=\"2\" width=\"20\" /\u003e \u003ccol min=\"3\" max=\"3\" width=\"20\" /\u003e \u003c/cols\u003e \u003csheetData\u003e \u003crow r=\"1\" spans=\"1:3\" x14ac:dyDescent=\"0.25\"\u003e \u003cc r=\"A1\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003ef1\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"B1\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003ef2\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"C1\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003ef3\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003c/row\u003e \u003crow r=\"2\" spans=\"1:3\" x14ac:dyDescent=\"0.25\"\u003e \u003cc r=\"A2\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e2 1\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"B2\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e2 2\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"C2\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e2 3\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003c/row\u003e \u003crow r=\"3\" spans=\"1:3\" x14ac:dyDescent=\"0.25\"\u003e \u003cc r=\"A3\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e3 1\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"B3\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e3 2\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003cc r=\"C3\" t=\"inlineStr\"\u003e \u003cis\u003e \u003ct\u003e3 3\u003c/t\u003e \u003c/is\u003e \u003c/c\u003e \u003c/row\u003e \u003c/sheetData\u003e \u003c/worksheet\u003e 其中，用于说明工作簿有多少列，以及每列的名称；由多个组成，每个代表工作簿的一行，每行由多个cell组成，用表示，为了简单起见，我们使用inlineStr类型来保存数据，数据放在标签中。 ","date":"2021-01-03","objectID":"/create-stream-xlsx/:2:3","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"根据数据生成流式xlsx文件 要生成流式xlsx文件，首先需要有能够支持流式生成zip文件的库，go和java的标准库都能支持，python的标准库不支持，需要使用第三方库python-zipstream或者ZipStream，C/C++需要自己实现，可以参考nginx zip module。 我实现了一个流式生成xlsx的go版本，供参考。 ","date":"2021-01-03","objectID":"/create-stream-xlsx/:3:0","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["golang"],"content":"流式HTTP文件下载 当需要传输文件流时，HTTP的header不发送Content-Length，在发送完headers后，将生成的流式xlsx数据写入socket即可。go的http handler的参数ResponseWriter是实现了io.Writer接口，可以直接写入生成的xlsx文件数据，比较简单，就不写例子了。 type Handler interface { ServeHTTP(ResponseWriter, *Request) } type ResponseWriter interface { // Header returns the header map that will be sent by // WriteHeader. The Header map also is the mechanism with which // Handlers can set HTTP trailers. // // Changing the header map after a call to WriteHeader (or // Write) has no effect unless the modified headers are // trailers. // // There are two ways to set Trailers. The preferred way is to // predeclare in the headers which trailers you will later // send by setting the \"Trailer\" header to the names of the // trailer keys which will come later. In this case, those // keys of the Header map are treated as if they were // trailers. See the example. The second way, for trailer // keys not known to the Handler until after the first Write, // is to prefix the Header map keys with the TrailerPrefix // constant value. See TrailerPrefix. // // To suppress automatic response headers (such as \"Date\"), set // their value to nil. Header() Header // Write writes the data to the connection as part of an HTTP reply. // // If WriteHeader has not yet been called, Write calls // WriteHeader(http.StatusOK) before writing the data. If the Header // does not contain a Content-Type line, Write adds a Content-Type set // to the result of passing the initial 512 bytes of written data to // DetectContentType. Additionally, if the total size of all written // data is under a few KB and there are no Flush calls, the // Content-Length header is added automatically. // // Depending on the HTTP protocol version and the client, calling // Write or WriteHeader may prevent future reads on the // Request.Body. For HTTP/1.x requests, handlers should read any // needed request body data before writing the response. Once the // headers have been flushed (due to either an explicit Flusher.Flush // call or writing enough data to trigger a flush), the request body // may be unavailable. For HTTP/2 requests, the Go HTTP server permits // handlers to continue to read the request body while concurrently // writing the response. However, such behavior may not be supported // by all HTTP/2 clients. Handlers should read before writing if // possible to maximize compatibility. Write([]byte) (int, error) // WriteHeader sends an HTTP response header with the provided // status code. // // If WriteHeader is not called explicitly, the first call to Write // will trigger an implicit WriteHeader(http.StatusOK). // Thus explicit calls to WriteHeader are mainly used to // send error codes. // // The provided code must be a valid HTTP 1xx-5xx status code. // Only one header may be written. Go does not currently // support sending user-defined 1xx informational headers, // with the exception of 100-continue response header that the // Server sends automatically when the Request.Body is read. WriteHeader(statusCode int) } ","date":"2021-01-03","objectID":"/create-stream-xlsx/:4:0","tags":["xlsx","zip","golang","java","python"],"title":"如何流式导出xlsx/zip文件","uri":"/create-stream-xlsx/"},{"categories":["mysql"],"content":"背景 最近正在做语音相关的工作，所有的语料数据都放在一个mysql数据库里面，同事一次误操作导致整个数据库被drop，里面包括了全部的文本语料和词库。 数据库放在一台linux机器上，文件系统是XFS。 从磁盘恢复数据 说实话，之前没有相关经验，只有先google一下看看有没有现成可以参考的解决方案。在stackexchange上看到有人提到TwinDB data recovery toolkit可以恢复，先需要停掉mysql，并停止一切写入，赶紧systemctl stop mysql，umount掉mysql database所在的disk。 MySQL 5.5之前是所有数据都放在ibdata1文件里面的，因此被删除的数据还在ibdata里面，而5.6之后是放在单独的目录里面，drop database/table是直接删除文件的。我们用的是8.0，不能直接扫描ibdata1，需要扫描整个磁盘，同时也意味着其他进程的写入也很可能导致数据被覆盖掉。不过既然是删除了文件，可以先试试能不能从xfs里面恢复删除的文件，找到一个工具，扫描了一遍磁盘，没能够找到对应的ibd文件。 ","date":"2020-12-22","objectID":"/recover-dropped-database/:0:0","tags":["mysql","c++","python","reverse engineering"],"title":"记一次MySQL删库的恢复","uri":"/recover-dropped-database/"},{"categories":["mysql"],"content":"TwinDB data recovery toolkit使用 先下载到本地编译 git clone https://github.com/twindb/undrop-for-innodb cd undrop-for-innodb make 使用stream_parser扫描整个磁盘 ./stream_parser /dev/sdc1 会在当前目录下生成一个文件夹pages-XXX，XXX为扫描的文件名，我这里生成的是pages-sdc1，里面包含了FIL_PAGE_INDEX和FIL_PAGE_BLOB两个目录。 使用c_parser得到表corpora的ID，0000000000000001.page是存放SYS_TABLES的page文件 ./c_parser -4f pages-sdc1/FIL_PAGE_INDEX/0000000000000001.page -t dictionary/SYS_TABLES.sql | grep corpora 000000000504 85000001320110 SYS_TABLES \"corpora\" 54 4 1 0 0 \"\" 1 因为InnoDB的数据是放在primary index上的，通过获取primary index的ID，就能够得到存放数据的page文件。0000000000000003.page是存放SYS_INDEXES的page文件 ./c_parser -4f pages-sdc1/FIL_PAGE_INDEX/0000000000000003.page -t dictionary/SYS_INDEXES.sql | grep 54 000000000504 85000001320178 SYS_INDEXES 54 112 \"PRIMARY\" 1 3 1 3 找到了corpora的数据是在0000000000000112.page文件里面的 在恢复数据之前需要先确定表结构，还好我们知道，创建一个包含corpora DDL的sql文件放到corpora.sql 恢复数据 mkdir -p dumps/default ./c_parser -6f pages-sdc1/FIL_PAGE_INDEX/0000000000000112.page \\ -t corpora.sql \u003e dumps/default/corpora 2\u003e dumps/default/corpora.sql 运行完成后，看看是否恢复成功 head -100 dumps/default/corpora 很遗憾，数据不全，而且还有很多错误数据，看来已经被覆盖掉了不少page。尝试恢复另外两张表也没什么收获。难道只能从删库到跑路了？ 从backup恢复 之前有做一个定时backup的脚本，每天半夜进行backup，赶紧到backup的机器上看看，结果发现最近一次的backup是3个月前的了。执行 crontab -l 是有对应的命令的，查了一下，有人说crontab命令后面必须有一行空行才能正确执行，还不确定是否是这个导致，顺手改掉，后面再定时检查。 从solr恢复 还好文字语料在solr中是有cache的，用于加速查询，赶紧连接到solr中，dump到文件中 curl \"http://solr-server/solr/corpora/select?q=*:*\u0026wt=csv\u0026indent=true\u0026rows=26159501\" -o corpora.csv 有了csv文件，写一个python脚本直接导入即可。 从内存中恢复 但是还有词表没恢复，这张表是没有solr缓存的，怎么办？ 还好，我们有一个在线分词查询程序，会将词表cache到内存中，这是一个python写的http server，分词是使用c++实现的DLL，运行在windows上。 词表保存在一个hash table里面，结构如下： struct Word { unsigned char nbytes; /* number of bytes */ char length; /* number of characters */ unsigned int freq; char text[word_embed_len]; }; struct Entry { Word *word; Entry *next; }; static Entry **bins = static_cast\u003cEntry **\u003e(std::calloc(init_size, sizeof(Entry *))); 从代码可以看出来，用的是Seperated chaining方式存放的，如下图： 怎么从内存中还原词表呢？有两种方法： ReadProcessMemory()：直接读取进程的内存空间 MiniDump文件：保存为Minidump文件，然后读取这个文件 我选择第二个，使用Process Explorer保存一个dump文件。这里需要注意，必须保存full dump，否则Heap不会保存，后续无法获取heap中的数据。 ","date":"2020-12-22","objectID":"/recover-dropped-database/:1:0","tags":["mysql","c++","python","reverse engineering"],"title":"记一次MySQL删库的恢复","uri":"/recover-dropped-database/"},{"categories":["mysql"],"content":"minidump文件格式 不像其他文件格式，MS对minidump文件的格式描述还是很清楚的，在这里可以找到。有人已经给我们写好了python解析minidump的库，我们只需要找到全局变量数组bins，然后遍历这个数组找出所有的Word即可。 ","date":"2020-12-22","objectID":"/recover-dropped-database/:2:0","tags":["mysql","c++","python","reverse engineering"],"title":"记一次MySQL删库的恢复","uri":"/recover-dropped-database/"},{"categories":["mysql"],"content":"定位变量地址 在windows中，一个进程运行时是有自己独立进程空间的，这个进程依赖的DLL都会作为module被加载到这个进程的地址空间中来，我们在minidump中可以找到这个DLL所在的base address，然后在这个DLL中定位到这个变量所在offset，两者相加即可得到这个变量在整个进程空间中的地址。 minidump中包含了所有module的相关信息，而变量的偏移地址，就需要借助一些其他方法来获取了。如果有DLL对应的PDB文件，则比较容易，但是这个DLL的PDB文件也没有保存下来，只能想其他办法。 使用IDA Pro，打开这个DLL，通过exported function，很容易定位到这个操作这个变量的函数，然后在这个函数中找到这个全局变量的位置，然后用这个地址减去IDA加载DLL时的base address，就得到了这个变量的offset。 有了offset，接下来就是遍历hash table了。这里我使用了python的struct库来进行数据的数据的读取。 ","date":"2020-12-22","objectID":"/recover-dropped-database/:3:0","tags":["mysql","c++","python","reverse engineering"],"title":"记一次MySQL删库的恢复","uri":"/recover-dropped-database/"},{"categories":["mysql"],"content":"读取minidump minidump这个库给我们提供了方便进行内存位置读取的方法，简化后的代码如下： from minidump.minidumpfile import MinidumpFile from minidump.minidumpreader import MinidumpFileReader import struct INT_SIZE = 4 PTR_SIZE = 8 class Word: def __init__(self, reader, ptr): self.reader = reader self.ptr = ptr buf = reader.read(ptr, 8) # ignore padding between length and freq self.nbytes, self.length, padding, self.freq = struct.unpack('\u003cBBHL', buf) if self.nbytes \u003e 0: self.text = reader.read(ptr + 8, self.nbytes).decode('utf8') else: self.text = '' def __str__(self): if self.nbytes \u003e 0: return 'text: {}, freq: {}'.format(self.text, self.freq) else: return '\u003cEMPTY\u003e' class Entry: def __init__(self, reader, ptr): self.reader = reader self.ptr = ptr self.word = None buf = reader.read(ptr, 2 * PTR_SIZE) self.pword, self.pnext = struct.unpack('\u003cQQ', buf) if self.pword != 0: self.word = Word(reader, self.pword) def __str__(self): if self.pword != 0: return '{}, pnext: {:x}'.format(self.word, self.pnext) else: return 'pnext:{:x}'.format(self.pnext) def process_entry(entry): pass def main(): mp = MinidumpFile.parse('python.dmp') reader = MinidumpFileReader(mp) dll = reader.get_module_by_name('XXX.dll') baseaddr = dll.baseaddress # get offset from IDA Pro p_n_bins = baseaddr + 0x1EA58 pp_bins = baseaddr + 0x1FD60 p_bins = struct.unpack('\u003cQ', reader.read(pp_bins, PTR_SIZE))[0] n_bins = struct.unpack('\u003cL', reader.read(p_n_bins, INT_SIZE))[0] print('p_n_bins: {:x}, n_bins: {:x}'.format(p_n_bins, n_bins)) for i in range(n_bins): pentry = struct.unpack('\u003cQ', reader.read( p_bins + i * PTR_SIZE, PTR_SIZE))[0] if pentry != 0: entry = Entry(reader, pentry) process_word(entry) while entry.pnext != 0: entry = Entry(reader, entry.pnext) process_entry(entry) if __name__ == '__main__': main() 总结 出现误删，一定要马上停止写入，umount磁盘，如果有可能，尽量保留磁盘镜像 数据库的权限如果没有设置好，会导致很容易就能删库跑路 数据库的备份没有起作用，一定要定时检查备份脚本是否正常工作 后面有时间对InnoDB的结构进行一下分析 ","date":"2020-12-22","objectID":"/recover-dropped-database/:4:0","tags":["mysql","c++","python","reverse engineering"],"title":"记一次MySQL删库的恢复","uri":"/recover-dropped-database/"},{"categories":["hugo"],"content":"Hugo/Hexo/Jekyll比较 考察了一下static web site generator，常用的有jekyll，hexo和hugo，我根据自己的情况，选择了Hugo。 Name Home Language Pro Con hugo https://gohugo.io/ golang 安装简单github star数多有问题可以自己解决 需要使用github action更新 jekyll https://jekyllrb.com/ ruby 老牌工具github star数最多github pages原生支持模板比较多 需要安装ruby速度慢介绍比较旧 hexo https://hexo.io/ JavaScript 中文文档比较好 需要使用github action更新 ","date":"2020-12-21","objectID":"/choose-static-generator/:0:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"Jekyll github pages官方文档中使用的是jekyll，之前ruby也没怎么用过，虽然与其他语言大同小异，但是用起来不够熟悉，导致很多步骤出现问题。 然后网上关于jekyll的文章很多都是4-5年前的。 github pages的版本是3.9.0，官方已经是4.2.0了。 jekyll官方还不支持windows，考虑到以后可能不止在一个平台写日志，这个已经是一个不小的缺点了。 安装gem和bundle的官方源太慢了，虽然可以替换国内mirror解决，第一次安装的时候停了好长时间才发现是网络问题，在心中又减了一分。最后，看源码和查找问题比较麻烦（还得先学ruby），果断放弃。 ","date":"2020-12-21","objectID":"/choose-static-generator/:1:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"Hexo Hexo是JavaScript的，虽然nodejs也经常用，但是自从用上golang和python后，已经尽量避免使用nodejs了，放弃。 Hexo的中文文档还是不错的。 ","date":"2020-12-21","objectID":"/choose-static-generator/:2:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"Hugo Hugo在star数量上跟jekyll相差不大，而且是golang实现，下载的时候官方release就一个可执行文件，安装太方便了，本来写blog就是要简单，如果环境搭建太麻烦就得不偿失了。 下面就详细讲一下Hugo的使用。 Hugo使用 ","date":"2020-12-21","objectID":"/choose-static-generator/:3:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"安装 在github release页面下载安装包，解压其中的可执行文件，将其路径加入到path中 ","date":"2020-12-21","objectID":"/choose-static-generator/:4:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"新建site 命令行输入 # 新建site hugo new site boolking.github.io cd boolking.github.io #初始化git git init . git add remote https://github.com/boolking/boolking.github.io ","date":"2020-12-21","objectID":"/choose-static-generator/:5:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"选择theme 到Hugo Themes选择一款主题，我使用的是第一个Hugo Future Imperfect Slim cd themes git submodule add https://github.com/pacollins/hugo-future-imperfect-slim.git ","date":"2020-12-21","objectID":"/choose-static-generator/:6:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"设置config.toml 参考wiki，修改自己的config.toml ","date":"2020-12-21","objectID":"/choose-static-generator/:7:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"启动local server 启动local server，打开browser，边编辑边看效果 hugo server -D -p 11111 ","date":"2020-12-21","objectID":"/choose-static-generator/:8:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"添加日志 使用hugo new命令添加一篇post hugo new blog/choose-static-generator.md 完成后可以在blog目录下看到新的md文件，将draft改为false，编辑保存后就能在本地看到。 ","date":"2020-12-21","objectID":"/choose-static-generator/:9:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["hugo"],"content":"使用github action来自动生成页面 我使用的是actions-gh-pages 添加github action文件到git中，然后每次push的时候，github action就会生成新的页面并上传到gh-pages分支。如果有问题可以在settings中的github pages相关设置中调整显示的分支和目录。 需要注意的是官方例子中监视的branch是main，如果使用的是master，需要修改为： on:push:branches:- master # Set a branch to deploy ","date":"2020-12-21","objectID":"/choose-static-generator/:10:0","tags":["jekyll","hexo","hugo"],"title":"静态网站生成工具选择","uri":"/choose-static-generator/"},{"categories":["meta"],"content":"从今天开始写blog了，将采用github pages，不定时更新。 ","date":"2020-12-21","objectID":"/my-first-post/:0:0","tags":[],"title":"第一篇日志","uri":"/my-first-post/"},{"categories":null,"content":"BOOLKING的技术笔记","date":"2020-12-20","objectID":"/about/","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"关于我 后端技术Leader，擅长C++/golang/python/Java逆向/二进制安全。 长期从事网络相关开发和团队管理工作。 ","date":"2020-12-20","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"}]